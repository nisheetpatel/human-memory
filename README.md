# About this project

This is the code repository for a project that aims to test whether, how, and how well humans encode values in their memory. We test the normative theory for allocating limited memory resources in reinforcement learning, which was originally originally proposed in [Patel et al. 2020, NeurIPS](https://papers.nips.cc/paper/2020/hash/c4fac8fb3c9e17a2f4553a001f631975-Abstract.html).

> :warning: Currently under development. Some parts of the code may not be functional! Please feel free to contact us for any questions.
> :warning: **The data is not hosted on github.** Hence, none of the files in src/analysis will work unless you have your own data. If none of the collaborators ([Luigi Acerbi](https://luigiacerbi.com/), [Alexandre](https://neurocenter-unige.ch/research-groups/alexandre-pouget/) [Pouget](https://neurocenter-unige.ch/research-groups/alexandre-pouget/), and [Antonio](https://neurocenter-unige.ch/research-groups/alexandre-pouget/) [Rangel](https://www.rnl.caltech.edu/)) have any objections, we will release the data when our work gets published.

# Installation

Install the required packages in a new environment using [mamba](https://github.com/mamba-org/mamba) with `mamba create --name <env_name> --file requirements.txt`, or using [conda](https://docs.conda.io/en/latest/) with `conda create --name <env_name> --file requirements.txt`, or in an existing environment using pip with `pip install -r requirements.txt`.
